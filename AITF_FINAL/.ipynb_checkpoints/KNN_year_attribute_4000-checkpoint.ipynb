{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b9e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "csv_file_path='top200_training.xls'\n",
    "#記得pip install xlrd\n",
    "df = pd.read_excel(csv_file_path)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9558967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'year_combinations.txt'\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# 將年月轉換為日期型數據\n",
    "df['年月'] = pd.to_datetime(df['年月'], format='%Y%m')\n",
    "\n",
    "# 獲取所有不同的年份\n",
    "all_years = ['1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008']\n",
    "\n",
    "# 開始的欄位\n",
    "start_column = '1997'\n",
    "\n",
    "# 開始欄位的索引\n",
    "start_index = all_years.index(start_column)\n",
    "\n",
    "# 創建一個字典來保存結果\n",
    "year_combinations_dict = {}\n",
    "\n",
    "# 生成所有可能的欄位組合\n",
    "for i in range(1, len(all_years) - start_index + 1):\n",
    "    for subset in combinations(all_years[start_index:], i):\n",
    "        selected_columns = list(subset)\n",
    "        # 將結果存入字典\n",
    "        year_combinations_dict[len(year_combinations_dict) + 1] = selected_columns\n",
    "\n",
    "# 打開一個檔案來保存結果\n",
    "with open('year_combinations.txt', 'w') as file:\n",
    "    # 遍歷字典，將結果寫入檔案\n",
    "    for key, value in year_combinations_dict.items():\n",
    "        file.write(f\"Key: {key}, Selected year: {value}\\n\")\n",
    "        # 在這裡進行你的分析或模型擬合等操作\n",
    "        # ...\n",
    "        file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# 提示保存成功\n",
    "print(\"Results saved to 'year_combinations.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88816f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'column_combinations_KNN_train.txt'\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 所有的欄位\n",
    "all_columns = ['股價淨值比', '股價營收比' ,'M淨值報酬率─稅後', 'M營業利益成長率', 'M稅後淨利成長率']\n",
    "\n",
    "# 開始的欄位\n",
    "start_column = '股價淨值比'\n",
    "\n",
    "# 開始欄位的索引\n",
    "start_index = all_columns.index(start_column)\n",
    "\n",
    "# 創建一個字典來保存結果\n",
    "column_combinations_dict = {}\n",
    "\n",
    "# 生成所有可能的欄位組合\n",
    "for i in range(1, len(all_columns) - start_index + 1):\n",
    "    for subset in combinations(all_columns[start_index:], i):\n",
    "        selected_columns = list(subset)\n",
    "        # 將結果存入字典\n",
    "        column_combinations_dict[len(column_combinations_dict) + 1] = selected_columns\n",
    "\n",
    "# 打開一個檔案來保存結果\n",
    "with open('column_combinations_KNN_train.txt', 'w') as file:\n",
    "    # 遍歷字典，將結果寫入檔案\n",
    "    for key, value in column_combinations_dict.items():\n",
    "        file.write(f\"Key: {key}, Selected Columns: {value}\\n\")\n",
    "        # 在這裡進行你的分析或模型擬合等操作\n",
    "        # ...\n",
    "        file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# 提示保存成功\n",
    "print(\"Results saved to 'column_combinations_KNN_train.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981ac3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共有test year:3\n",
      "Number of rows in train_data: 1800\n",
      "Optimal k value for minimum error rate: 88\n",
      "1997\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[86 23]\n",
      " [63 28]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.79      0.67       109\n",
      "           1       0.55      0.31      0.39        91\n",
      "\n",
      "    accuracy                           0.57       200\n",
      "   macro avg       0.56      0.55      0.53       200\n",
      "weighted avg       0.56      0.57      0.54       200\n",
      "\n",
      "新數據的預測準確率: 0.57\n",
      "0.8858914901960784\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[163, 196, 7, 136, 156]\n",
      "163    高林         \n",
      "196    中連         \n",
      "7      大同         \n",
      "136    中紡         \n",
      "156    瑞昱         \n",
      "Name: 簡稱, dtype: object\n",
      "163   -22.6782\n",
      "196    -5.8148\n",
      "7       1.5517\n",
      "136   -33.6004\n",
      "156    -2.4571\n",
      "Name: Return, dtype: float64\n",
      "0.8740024\n",
      "1999\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[79 32]\n",
      " [58 31]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.71      0.64       111\n",
      "           1       0.49      0.35      0.41        89\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.53      0.53      0.52       200\n",
      "weighted avg       0.54      0.55      0.54       200\n",
      "\n",
      "新數據的預測準確率: 0.55\n",
      "0.5790330317460317\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[7, 107, 111, 52, 149]\n",
      "407     日月光       \n",
      "507    新纖         \n",
      "511    遠百         \n",
      "452    台肥         \n",
      "549    藍天         \n",
      "Name: 簡稱, dtype: object\n",
      "407   -73.8927\n",
      "507   -65.3430\n",
      "511   -17.6796\n",
      "452   -52.4127\n",
      "549   -77.2687\n",
      "Name: Return, dtype: float64\n",
      "0.42680660000000004\n",
      "2005\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[83 29]\n",
      " [64 24]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.74      0.64       112\n",
      "           1       0.45      0.27      0.34        88\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.51      0.51      0.49       200\n",
      "weighted avg       0.52      0.54      0.51       200\n",
      "\n",
      "新數據的預測準確率: 0.535\n",
      "1.2678076320754716\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[2, 101, 43, 13, 81]\n",
      "1602    聯電         \n",
      "1701    東陽         \n",
      "1643    勝華         \n",
      "1613    遠傳         \n",
      "1681    華通         \n",
      "Name: 簡稱, dtype: object\n",
      "1602    12.7045\n",
      "1701   -33.9846\n",
      "1643   -31.1336\n",
      "1613     8.0546\n",
      "1681   -18.9929\n",
      "Name: Return, dtype: float64\n",
      "0.873296\n",
      "{1997: 0.8858914901960784, 1999: 0.5790330317460317, 2005: 1.2678076320754716}\n",
      "年均化複利為:0.21677838497002747\n",
      "\n",
      "\n",
      "{1997: 0.8740024, 1999: 0.42680660000000004, 2005: 0.873296}\n",
      "年均化複利為:0.10858853351207938\n",
      "ori sum2:0.32576560053623815\n",
      "test years have:3\n",
      "after sum2:0.10858853351207938\n",
      "Optimal k value for minimum error rate: 24\n",
      "1997\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[82 27]\n",
      " [61 30]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.75      0.65       109\n",
      "           1       0.53      0.33      0.41        91\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.55      0.54      0.53       200\n",
      "weighted avg       0.55      0.56      0.54       200\n",
      "\n",
      "新數據的預測準確率: 0.56\n",
      "0.8735105614035088\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[163, 196, 45, 55, 26]\n",
      "163    高林         \n",
      "196    中連         \n",
      "45     南紡         \n",
      "55      震旦行       \n",
      "26     矽品         \n",
      "Name: 簡稱, dtype: object\n",
      "163   -22.6782\n",
      "196    -5.8148\n",
      "45    -26.0263\n",
      "55    -16.1681\n",
      "26      2.0266\n",
      "Name: Return, dtype: float64\n",
      "0.8626784000000001\n",
      "1999\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[81 30]\n",
      " [64 25]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.73      0.63       111\n",
      "           1       0.45      0.28      0.35        89\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.51      0.51      0.49       200\n",
      "weighted avg       0.51      0.53      0.51       200\n",
      "\n",
      "新數據的預測準確率: 0.53\n",
      "0.5747047818181819\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[80, 117, 59, 125, 159]\n",
      "480     光寶科       \n",
      "517    可成         \n",
      "459    友訊         \n",
      "525    豐泰         \n",
      "559    榮化         \n",
      "Name: 簡稱, dtype: object\n",
      "480   -22.7152\n",
      "517   -75.0269\n",
      "459   -49.3240\n",
      "525   -36.8932\n",
      "559   -23.9837\n",
      "Name: Return, dtype: float64\n",
      "0.584114\n",
      "2005\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[82 30]\n",
      " [60 28]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.73      0.65       112\n",
      "           1       0.48      0.32      0.38        88\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.53      0.53      0.51       200\n",
      "weighted avg       0.54      0.55      0.53       200\n",
      "\n",
      "新數據的預測準確率: 0.55\n",
      "1.2811099568965516\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[130, 37, 42, 85, 121]\n",
      "1730     統一實       \n",
      "1637    裕隆         \n",
      "1642     英業達       \n",
      "1685    技嘉         \n",
      "1721    群光         \n",
      "Name: 簡稱, dtype: object\n",
      "1730    106.6784\n",
      "1637     17.7864\n",
      "1642     40.0955\n",
      "1685    -15.5881\n",
      "1721     75.4355\n",
      "Name: Return, dtype: float64\n",
      "1.4488154\n",
      "{1997: 0.8735105614035088, 1999: 0.5747047818181819, 2005: 1.2811099568965516}\n",
      "年均化複利為:0.2143769672973872\n",
      "\n",
      "\n",
      "{1997: 0.8626784000000001, 1999: 0.584114, 2005: 1.4488154}\n",
      "年均化複利為:0.24335391564045714\n",
      "ori sum2:0.7300617469213714\n",
      "test years have:3\n",
      "after sum2:0.24335391564045714\n",
      "Optimal k value for minimum error rate: 5\n",
      "1997\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[71 38]\n",
      " [55 36]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.65      0.60       109\n",
      "           1       0.49      0.40      0.44        91\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.52      0.52      0.52       200\n",
      "weighted avg       0.53      0.54      0.53       200\n",
      "\n",
      "新數據的預測準確率: 0.535\n",
      "0.8107308513513514\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[72, 179, 183, 152, 93]\n",
      "72     凌陽         \n",
      "179    台揚         \n",
      "183    民興         \n",
      "152    亞聚         \n",
      "93     嘉泥         \n",
      "Name: 簡稱, dtype: object\n",
      "72     21.4721\n",
      "179   -15.1038\n",
      "183    -8.2347\n",
      "152   -16.2685\n",
      "93    -27.6940\n",
      "Name: Return, dtype: float64\n",
      "0.9083422\n",
      "1999\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[68 43]\n",
      " [52 37]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.61      0.59       111\n",
      "           1       0.46      0.42      0.44        89\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.51      0.51      0.51       200\n",
      "weighted avg       0.52      0.53      0.52       200\n",
      "\n",
      "新數據的預測準確率: 0.525\n",
      "0.54915355\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[5, 143, 118, 183, 57]\n",
      "405    廣達         \n",
      "543     偉詮電       \n",
      "518    亞旭         \n",
      "583    巨大         \n",
      "457    飛瑞         \n",
      "Name: 簡稱, dtype: object\n",
      "405   -51.2020\n",
      "543   -36.4522\n",
      "518   -65.5172\n",
      "583    58.8640\n",
      "457   -29.9773\n",
      "Name: Return, dtype: float64\n",
      "0.7514306\n",
      "2005\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[65 47]\n",
      " [51 37]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.58      0.57       112\n",
      "           1       0.44      0.42      0.43        88\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.50      0.50      0.50       200\n",
      "weighted avg       0.51      0.51      0.51       200\n",
      "\n",
      "新數據的預測準確率: 0.51\n",
      "1.2857899161904762\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[153, 6, 48, 89, 124]\n",
      "1753     新日興       \n",
      "1606    友達         \n",
      "1648    力成         \n",
      "1689    喬山         \n",
      "1724    華冠         \n",
      "Name: 簡稱, dtype: object\n",
      "1753    90.2066\n",
      "1606    -3.0462\n",
      "1648    52.9836\n",
      "1689    90.3988\n",
      "1724   -22.1918\n",
      "Name: Return, dtype: float64\n",
      "1.416702\n",
      "{1997: 0.8107308513513514, 1999: 0.54915355, 2005: 1.2857899161904762}\n",
      "年均化複利為:0.1908179632937208\n",
      "\n",
      "\n",
      "{1997: 0.9083422, 1999: 0.7514306, 2005: 1.416702}\n",
      "年均化複利為:0.3223262088269212\n",
      "ori sum2:0.9669786264807636\n",
      "test years have:3\n",
      "after sum2:0.3223262088269212\n",
      "Optimal k value for minimum error rate: 21\n",
      "1997\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[72 37]\n",
      " [56 35]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.66      0.61       109\n",
      "           1       0.49      0.38      0.43        91\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.52      0.52      0.52       200\n",
      "weighted avg       0.53      0.54      0.53       200\n",
      "\n",
      "新數據的預測準確率: 0.535\n",
      "0.789608736111111\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[111, 87, 158, 157, 62]\n",
      "111    燁輝         \n",
      "87     美式         \n",
      "158    東泥         \n",
      "157    福聚         \n",
      "62     大陸         \n",
      "Name: 簡稱, dtype: object\n",
      "111   -27.8249\n",
      "87      4.9370\n",
      "158   -30.7763\n",
      "157     2.4320\n",
      "62    -42.3973\n",
      "Name: Return, dtype: float64\n",
      "0.812741\n",
      "1999\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[77 34]\n",
      " [49 40]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.69      0.65       111\n",
      "           1       0.54      0.45      0.49        89\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.58      0.57      0.57       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "新數據的預測準確率: 0.585\n",
      "0.5551261351351351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[11, 175, 83, 85, 28]\n",
      "411    大同         \n",
      "575    佳和         \n",
      "483    博達         \n",
      "485     統一實       \n",
      "428    精業         \n",
      "Name: 簡稱, dtype: object\n",
      "411   -67.1492\n",
      "575   -65.5719\n",
      "483   -37.6195\n",
      "485   -48.9028\n",
      "428   -74.0175\n",
      "Name: Return, dtype: float64\n",
      "0.4134782\n",
      "2005\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[79 33]\n",
      " [59 29]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.71      0.63       112\n",
      "           1       0.47      0.33      0.39        88\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.52      0.52      0.51       200\n",
      "weighted avg       0.53      0.54      0.52       200\n",
      "\n",
      "新數據的預測準確率: 0.54\n",
      "1.292692403548387\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[113, 145, 52, 117, 92]\n",
      "1713    遠雄         \n",
      "1745    巨擘         \n",
      "1652    世界         \n",
      "1717    燦坤         \n",
      "1692    精英         \n",
      "Name: 簡稱, dtype: object\n",
      "1713    166.9087\n",
      "1745    -11.2854\n",
      "1652      5.8665\n",
      "1717    -30.5256\n",
      "1692    -10.3693\n",
      "Name: Return, dtype: float64\n",
      "1.2411898\n",
      "{1997: 0.789608736111111, 1999: 0.5551261351351351, 2005: 1.292692403548387}\n",
      "年均化複利為:0.18887634103452192\n",
      "\n",
      "\n",
      "{1997: 0.812741, 1999: 0.4134782, 2005: 1.2411898}\n",
      "年均化複利為:0.13903422781039626\n",
      "ori sum2:0.4171026834311888\n",
      "test years have:3\n",
      "after sum2:0.13903422781039626\n",
      "Optimal k value for minimum error rate: 49\n",
      "1997\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[72 37]\n",
      " [63 28]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.66      0.59       109\n",
      "           1       0.43      0.31      0.36        91\n",
      "\n",
      "    accuracy                           0.50       200\n",
      "   macro avg       0.48      0.48      0.47       200\n",
      "weighted avg       0.49      0.50      0.48       200\n",
      "\n",
      "新數據的預測準確率: 0.5\n",
      "0.8387462461538461\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[11, 46, 180, 181, 150]\n",
      "11     茂矽         \n",
      "46     士紙         \n",
      "180    精業         \n",
      "181     鼎創達       \n",
      "150    永信         \n",
      "Name: 簡稱, dtype: object\n",
      "11     -10.8920\n",
      "46     -17.5994\n",
      "180    120.0200\n",
      "181     12.6574\n",
      "150     41.3854\n",
      "Name: Return, dtype: float64\n",
      "1.2911428\n",
      "1999\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[70 41]\n",
      " [53 36]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.63      0.60       111\n",
      "           1       0.47      0.40      0.43        89\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.52      0.52      0.52       200\n",
      "weighted avg       0.52      0.53      0.53       200\n",
      "\n",
      "新數據的預測準確率: 0.53\n",
      "0.5714114025974026\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[104, 76, 176, 22, 126]\n",
      "504    東雲         \n",
      "476    精英         \n",
      "576    永信         \n",
      "422     英業達       \n",
      "526    D 致伸       \n",
      "Name: 簡稱, dtype: object\n",
      "504   -85.0053\n",
      "476   -64.5058\n",
      "576   -12.3097\n",
      "422   -57.2471\n",
      "526   -57.5282\n",
      "Name: Return, dtype: float64\n",
      "0.4468078000000001\n",
      "2005\n",
      "Number of rows in test_data: 200\n",
      "confusion_matrix:\n",
      "[[82 30]\n",
      " [68 20]]\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.73      0.63       112\n",
      "           1       0.40      0.23      0.29        88\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.47      0.48      0.46       200\n",
      "weighted avg       0.48      0.51      0.48       200\n",
      "\n",
      "新數據的預測準確率: 0.51\n",
      "1.1645281588\n",
      "最近鄰居中預測值為1的前5筆索引:\n",
      "[140, 173, 48, 184, 159]\n",
      "1740    明泰         \n",
      "1773    精業         \n",
      "1648    力成         \n",
      "1784    大田         \n",
      "1759     潤泰全       \n",
      "Name: 簡稱, dtype: object\n",
      "1740     -1.1623\n",
      "1773   -100.0000\n",
      "1648     52.9836\n",
      "1784      6.0150\n",
      "1759     94.3675\n",
      "Name: Return, dtype: float64\n",
      "1.1044076\n",
      "{1997: 0.8387462461538461, 1999: 0.5714114025974026, 2005: 1.1645281588}\n",
      "年均化複利為:0.18604081429102107\n",
      "\n",
      "\n",
      "{1997: 1.2911428, 1999: 0.4468078000000001, 2005: 1.1044076}\n",
      "年均化複利為:0.2123748844996477\n",
      "ori sum2:0.6371246534989431\n",
      "test years have:3\n",
      "after sum2:0.2123748844996477\n"
     ]
    }
   ],
   "source": [
    "max_ret=5.027920323651434\n",
    "ans={}\n",
    "list_ans=[]\n",
    "#選擇特定欄位分析\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import islice\n",
    "cols=127968\n",
    "\n",
    "start_index = 4000  # 第3001筆資料的索引\n",
    "end_index = 4094  # 最後一筆資料的索引\n",
    "\n",
    "selected_range = islice(year_combinations_dict.items(), start_index, end_index + 1)\n",
    "#selected_range = islice(year_combinations_dict.items(), 4094) #4094是所有可用來訓練的年份組合\n",
    "\n",
    "\n",
    "with open('KNN_train_test_result_4000.txt', 'a') as file:\n",
    "    for key, selected_years in selected_range:\n",
    "        \n",
    "        # 選擇訓練集年分\n",
    "        train_years = [int(year) for year in selected_years]\n",
    "        #print(train_years)\n",
    "\n",
    "        #print(\"---------------------\")\n",
    "        # 選擇測試集年分\n",
    "        test_years = [int(year) for year in all_years if year not in selected_years]\n",
    "        print(f'總共有test year:{len(test_years)}')\n",
    "        \n",
    "        # 根據年份選擇訓練集\n",
    "        train_data = df[df['年月'].dt.year.isin(train_years)]\n",
    "        print(f\"Number of rows in train_data: {len(train_data)}\")\n",
    "        #print(train_data)\n",
    "        \n",
    "        # 排除指定列，並標準化\n",
    "        #columns_to_exclude = ['簡稱', '證券代碼', '年月', 'ReturnMean_year_Label', 'Return']\n",
    "        #features_to_scale_train = train_data.drop(columns=columns_to_exclude)\n",
    "        #features_to_scale_test = test_data.drop(columns=columns_to_exclude)\n",
    "    \n",
    "        for col in range (1,32):#取top10組合的前幾大frquency的屬性組合測試\n",
    "            cols=cols+1\n",
    "            list_ans=[]\n",
    "            # 指定要選擇的欄位\n",
    "            selected_columns = column_combinations_dict[col]\n",
    "            list_ans.append(selected_columns)\n",
    "            \n",
    "            # 選擇指定的欄位\n",
    "            features_to_scale_train = train_data[selected_columns]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaled_features_train = scaler.fit_transform(features_to_scale_train)\n",
    "            \n",
    "            # 轉換為dataframe\n",
    "            df_feat_train = pd.DataFrame(scaled_features_train, columns=features_to_scale_train.columns)\n",
    "            \n",
    "        #---------------------------------------------------------------------------------------------\n",
    "            # 分割訓練集和測試集\n",
    "            X_train = df_feat_train\n",
    "            y_train = train_data['ReturnMean_year_Label']\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.3,random_state=101)\n",
    "  \n",
    "        #--------------------------------------------------------------------------------------------------\n",
    "            error_rate = []\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            for i in range(1, 100):\n",
    "                knn = KNeighborsClassifier(n_neighbors=i, p=2, weights='distance', algorithm='brute')\n",
    "                knn.fit(X_train, y_train)\n",
    "                pred_i = knn.predict(X_test)\n",
    "                error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "            # 將k=1~60的錯誤率製圖畫出。k=23之後，錯誤率就在5-6%之間震盪。\n",
    "            #plt.figure(figsize=(10, 6))\n",
    "            #plt.plot(range(1, 100), error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "            #plt.title('Error Rate vs. K Value')\n",
    "            #plt.xlabel('K')\n",
    "            #plt.ylabel('Error Rate')\n",
    "            #plt.show()\n",
    "        #--------------------------------------------------------------------------------------------------\n",
    "            min_error = min(error_rate)\n",
    "            optimal_k = error_rate.index(min_error) + 1  # Adding 1 because Python indexing starts from 0\n",
    "\n",
    "            print(f\"Optimal k value for minimum error rate: {optimal_k}\")\n",
    "            #print(f\"Minimum Error Rate: {min_error}\")\n",
    "            list_ans.append(optimal_k)\n",
    "        #--------------------------------------------------------------------------------------------------\n",
    "            #使用KNN演算法\n",
    "            clf=KNeighborsClassifier(n_neighbors=optimal_k,p=2,weights='distance',algorithm='brute')\n",
    "            clf.fit(X_train,y_train)\n",
    "        #--------------------------------------------------------------------------------------------------\n",
    "            predict_label1={}\n",
    "            predict_k_pre5={}\n",
    "        #--------------------------------------------------------------------------------------------------\n",
    "\n",
    "            for year in test_years:\n",
    "                \n",
    "                # 選擇特定年份的 test_data\n",
    "                test_data = df[df['年月'].dt.year == year]\n",
    "                print(year)\n",
    "                #print(test_data)\n",
    "                print(f\"Number of rows in test_data: {len(test_data)}\")\n",
    "                \n",
    "                # 選擇指定的欄位\n",
    "                features_to_scale_test = test_data[selected_columns]\n",
    "                # 使用之前訓練好的標準化物件進行標準化\n",
    "                scaled_features_test = scaler.transform(features_to_scale_test)\n",
    "                # 將標準化後的特徵資料轉換為 DataFrame\n",
    "                df_feat_test = pd.DataFrame(scaled_features_test, columns=features_to_scale_test.columns)\n",
    "\n",
    "                \n",
    "                # 使用已經訓練好的模型進行預測\n",
    "                predictions_new = clf.predict(df_feat_test)\n",
    "\n",
    "                #------------------------------\n",
    "                #測試KNN演算法的好壞\n",
    "                from sklearn.metrics import classification_report,confusion_matrix\n",
    "                #將實際類別分為真正例（True Positive）、真負例（True Negative）、偽正例（False Positive）和偽負例（False Negative）\n",
    "                print('confusion_matrix:')\n",
    "                print(confusion_matrix(test_data['ReturnMean_year_Label'],predictions_new))\n",
    "\n",
    "                #模型的精確度、召回率、F1分數和支持數等指標，用來評估模型對於每個類別的預測性能。\n",
    "                print('classification_report')\n",
    "                print(classification_report(test_data['ReturnMean_year_Label'],predictions_new))\n",
    "\n",
    "                # 比較預測結果\n",
    "                accuracy_new = clf.score(df_feat_test, test_data['ReturnMean_year_Label'])\n",
    "                print(f'新數據的預測準確率: {accuracy_new}')\n",
    "                #---------------------------------------\n",
    "                #print(predictions_new)\n",
    "\n",
    "                #predicted_positive_indices = (predictions_new == 1)\n",
    "\n",
    "                # 獲取股票名稱\n",
    "                #predicted_positive_stock_names = new.loc[predicted_positive_indices, '簡稱']\n",
    "\n",
    "                # 設定檔案名稱\n",
    "                #output_file_name = 'selected_stocks_1998.csv'\n",
    "\n",
    "                # 匯出成 CSV 檔案\n",
    "                #predicted_positive_stock_names.to_csv(output_file_name, index=True)\n",
    "\n",
    "                # 預測要投資的股票名稱\n",
    "                #print(\"選擇股票:\")\n",
    "                #print(predicted_positive_stock_names)\n",
    "\n",
    "\n",
    "                # 選擇預測為1的股票\n",
    "                selected_stocks = test_data[predictions_new == 1]\n",
    "\n",
    "                # 計算return\n",
    "                stock_returns = selected_stocks['Return']\n",
    "\n",
    "                portfolio_returns = (stock_returns.mean()/100)+1\n",
    "\n",
    "                print(portfolio_returns)\n",
    "                predict_label1[year]=portfolio_returns\n",
    "\n",
    "                # 使用 kneighbors 方法取得最近鄰居的索引和距離\n",
    "                distances, indices = clf.kneighbors(df_feat_test, n_neighbors=5)\n",
    "\n",
    "                # 合併所有測試樣本的最近鄰居索引\n",
    "                all_indices = np.concatenate(indices)\n",
    "                all_distances = np.concatenate(distances)\n",
    "\n",
    "                # 將索引和距離組合成一個 2D 陣列，方便排序\n",
    "                combined_data = np.column_stack((all_indices, all_distances))\n",
    "\n",
    "                # 按照距離重新排序\n",
    "                sorted_combined_data = combined_data[np.argsort(combined_data[:, 1])]\n",
    "\n",
    "                # 選取最近鄰居中預測值為1的前5筆，且不重複\n",
    "                selected_indices = set()\n",
    "                i = 0\n",
    "                while len(selected_indices) < 5 and i < len(sorted_combined_data):\n",
    "                    index = int(sorted_combined_data[i, 0])\n",
    "                    if(index>=200 and index<400):\n",
    "                        index=index-200\n",
    "                    elif(index>=400 and index<600):\n",
    "                        index=index-400\n",
    "                    elif(index>=600 and index<800):\n",
    "                        index=index-600\n",
    "                    elif(index>=800 and index<1000):\n",
    "                        index=index-800\n",
    "                    elif(index>=1000 and index<1200):\n",
    "                        index=index-1000\n",
    "                    elif(index>=1200 and index<1400):\n",
    "                        index=index-1200\n",
    "                    elif(index>=1400 and index<1600):\n",
    "                        index=index-1400\n",
    "                    elif(index>=1600 and index<1800):\n",
    "                        index=index-1600\n",
    "                    elif(index>=1800 and index<2000):\n",
    "                        index=index-1800\n",
    "                    elif(index>=2000 and index<2200):\n",
    "                        index=index-2000\n",
    "                    elif(index>=2200 and index<2400):\n",
    "                        index=index-2200\n",
    "                    elif(index>=2400 and index<2600):\n",
    "                        index=index-2400\n",
    "                    elif(index>=2600 and index<2800):\n",
    "                        index=index-2600\n",
    "                    elif(index>=2800 and index<3000):\n",
    "                        index=index-2800\n",
    "                    elif(index>=3000 and index<3200):\n",
    "                        index=index-3000\n",
    "                    prediction = predictions_new[index]\n",
    "                    if prediction == 1 and index not in selected_indices:\n",
    "                        selected_indices.add(index)\n",
    "                    i += 1\n",
    "\n",
    "                # 將選取的索引轉換成列表\n",
    "                selected_indices_list = list(selected_indices)\n",
    "\n",
    "                # 打印最近鄰居中預測值為1的前5筆索引\n",
    "                print(\"最近鄰居中預測值為1的前5筆索引:\")\n",
    "                print(selected_indices_list)\n",
    "                select = test_data\n",
    "                # 獲取股票名稱\n",
    "                selects_stock = select.iloc[selected_indices_list]['簡稱']\n",
    "                print(selects_stock)\n",
    "                # 獲取股票return\n",
    "                selects_ret = select.iloc[selected_indices_list]['Return']\n",
    "                print(selects_ret)\n",
    "                with open(f'selected_stock_KNN_train_4000/{cols}.txt', 'a') as stockfile:\n",
    "                    stockfile.write(selects_stock.to_string())\n",
    "                    stockfile.write('\\n')\n",
    "                    stockfile.write(selects_ret.to_string())\n",
    "                # 計算return\n",
    "                stock_returns = (selects_ret.mean() / 100)+1\n",
    "                portfolio_returns = stock_returns\n",
    "                print(portfolio_returns)\n",
    "                predict_k_pre5[year] = portfolio_returns\n",
    "                #print(stock_returns)\n",
    "            sum1=1\n",
    "            sum2=1\n",
    "            print(predict_label1)\n",
    "            for k in predict_label1.keys():\n",
    "                if not (predict_label1[k]==0):\n",
    "                    sum1=predict_label1[k]*sum1\n",
    "            print(f'年均化複利為:{sum1/int(len(test_years))}')\n",
    "            print('\\n')\n",
    "            print(predict_k_pre5)\n",
    "            for k in predict_k_pre5.keys():\n",
    "                if not (predict_k_pre5[k]==0):\n",
    "                    sum2=predict_k_pre5[k]*sum2\n",
    "            print(f'年均化複利為:{sum2/int(len(test_years))}')\n",
    "            #list_ans.append(sum2/len(test_data)/200)\n",
    "            print(f'ori sum2:{sum2}')\n",
    "            print(f'test years have:{int(len(test_years))}')\n",
    "            sum2=sum2/int(len(test_years))\n",
    "            print(f'after sum2:{sum2}')\n",
    "            list_ans.append(sum2)\n",
    "            ans[cols]=list_ans\n",
    "            file.write(f'{cols}:{list_ans}\\n\\n')\n",
    "            file.flush()  # 強制將緩衝區內容寫入檔案\n",
    "            if(sum2>max_ret):\n",
    "                max_ret=sum2\n",
    "                with open('max_KNN_train_4000.txt', 'w') as maxfile:\n",
    "                    maxfile.write(f'max:train_year:{train_years},test_year:{test_years}:{cols}:{list_ans}\\n\\n')\n",
    "                    maxfile.flush()  # 強制將緩衝區內容寫入檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915fd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
